<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">

  <title>AI Without Python</title>

  <meta name="description" content="Slides for an introductory talk about AI and ML for C++ programmers">
  <meta name="author" content="Borislav Stanimirov">

  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  <link rel="stylesheet" href="../lib/reveal.js-3.8.0/css/reveal.min.css" />
  <link rel="stylesheet" href="../lib/reveal.js-3.8.0/css/theme/simple.min.css" id="theme" />
  <link rel="stylesheet" href="../lib/slides.css" />

  <!-- For syntax highlighting -->
  <link rel="stylesheet" href="/third_party/highlight-new/styles/github-gist.css">

  <!-- Slides-specific styles -->
  <link rel="stylesheet" href="custom.css">

  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ?
      'https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.8.0/css/print/pdf.min.css' :
      'https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.8.0/css/print/paper.min.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>

  <!--[if lt IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.8.0/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>

<body>

  <div class="reveal">
    <div class="slides">
      <section class="title">
        <h1>AI Without Python</h1>
        <h2>An Intro to Machine Learning for C++ Programmers</h2>
        <br/>
        <p>
          <a href="http://ibob.bg">Borislav Stanimirov</a> / <a href="https://twitter.com/stanimirovb">@stanimirovb</a>
        </p>
      </section>

      <section class="slide">
        <h3>Hello, World</h3>
        <br/>
        <pre><code class="cpp hljs" data-noescape>
  #include &lt;iostream&gt;

  int main()
  {
      std::cout &lt;&lt; "Hi, I'm Borislav!\n";
      std::cout &lt;&lt; "These slides are here: <span class="fragment hl-code">https://is.gd/aicppintro</span>\n";
      return 0;
  }
        </code></pre>
      </section>

      <section class="slide">
        <h3>Borislav Stanimirov</h3>
        <br/>
        <ul>
          <li>I mostly write <span class="fancy">C++</span></li>
          <li>Professionally since 2002</li>
          <li>2006&mdash;2018: <span class="fancy">game development</span></li>
          <li>2019&mdash;2023: <span class="fancy">medical software</span></li>
          <li>2023&mdash;now: <span class="fancy">machine learning</span></li>
          <li><span class="fancy">Open source</span>: <a href="https://github.com/iboB" target="_blank">github.com/iboB</a></li>
        </ul>
      </section>

      <section class="slide">
        <h3>This talk</h3>
        <br/>
        <ul>
          <li>&#x26a0;&#xfe0f; More <span class="fancy">inspirational</span> than educational</li>
          <li>&#x26a0;&#xfe0f; Contains <span class="fancy">personal opinion</span> on software</li>
          <li>More <span class="fancy">technical</span> than philosophical</li>
          <li>The <span class="fancy">gist</span>, rather than the detail</li>
          <li>Mainly for programmers who are <span class="fancy">not</span> in the ML field</li>
          <li>... and who have experience or interest in <span class="fancy">low-level</span></li>
          <li>Themes</li>
          <ul>
            <li><em>Why should you consider this?</em></li>
            <li><em>What can you do?</em></li>
          </ul>
        </ul>
      </section>

      <section>
        <h2>Background</h2>
        <h3>Machine Learning in 2023</h3>
      </section>

      <section>
        <h3>The Current <span class="fancy">Big Thing&trade;</span> in software</h3>
      </section>

      <section>
        <p>Whisper, DALL&middot;E, Craiyon &#x1f58d;, ChatGPT, GPT-J, LLaMa &#x1f999;, LaMDA,
          Midjourney, Falcon LLM &#x1f985;, Stable Diffusion, Unstable Diffusion &#x1f609;,
          GitHub Copilot, StarCoder, BERT &#x1F43B;, SAM, Chinchilla &#x1F42D;</p>
        <p>&hellip;</p>
      </section>

      <section>
        <p>A Cambrian explosion of AI tools</p>
        <p>... and startups</p>
        <p>... and software as a whole</p>
      </section>

      <section>
        <p>There's something new every day.</p>
        <small>(this talk will probably be outdated by tomorrow)</small>
      </section>

      <section>
        <p>This software is <span class="fancy">no magic</span></p>
      </section>

      <section class="slide">
        <h3>Modern AI Software</h3>
        <br/>
        <ul>
          <li>In many regards software <span class="fancy">like any other</span></li>
          <li>Written by teams <span>(of humans)</span></li>
          <li>...with conventional software development tools</li>
          <li>It has <em>some</em> unusual, <span class="fancy">but not unique</span>, features</li>
          <li>Many libraries and frameworks exist to help</li>
          <li>It's most often done in <span class="fancy">Python</span></li>
        </ul>
      </section>

      <section class="slide">
        <h3>Python Stacks</h3>
        <br/>
        <ul>
          <li>The big fish: <span class="fancy">PyTorch</span> and <span class="fancy">TensorFlow</span></li>
          <li>Every ML framwork has a Python front end</li>
          <li>Why Python?</li>
        </ul>
        <p class="pinner"><img class="diagram" src="../xmem-shared-ptr/dunno.jpg"/></p>
      </section>

      <section>
        <p>&#x26a0;&#xfe0f; Personal opinion time &#x26a0;&#xfe0f;</p>
      </section>

      <section class="slide">
        <h3>Borislav on Python</h3>
        <br/>
        <ul>
          <li>Is Python the best language for ML?</li>
          <ul>
            <li>No.</li>
          </ul>
          <li>It it the worst language for ML?</li>
          <ul>
            <li>No. But it's down there</li>
          </ul>
          <li><span class="fancy">Extreme care</span> is needed for software in duck-typed languages</li>
          <li>Python stacks are <span class="fancy">a mess</span></li>
        </ul>
      </section>

      <section>
        <img src="node_modules.png" />
      </section>

      <section class="slide">
        <h3>Python Stacks</h3>
        <br/>
        <ul>
          <li>Package managers: pip, pipenv, poetry, npm, conda</li>
          <li>Env managers: conda, mamba, pyenv, containers</li>
          <li>Notebooks and <span class="fancy"><em>Scientific</em> code</span></li>
        </ul>
      </section>

      <section>
        <h3>Modern ML software</h3>
        <img class="diagram" src="../unrealized-alpha/moms-spaghetti.jpg" />
      </section>

      <section>
        <img class="diagram" src="eye-of-providence.png" />
        <h3>Objective Truth</h3>
      </section>

      <section>
        <p>Python is slow</p>
        <img class="diagram" src="python-slow.jpg" />
      </section>

      <section>
        <p><span class="fancy">"No it's not slow!"</span></p>
        <ul>
          <li>"This Python program is faster than its C++ equivalent!"</li>
          <li>"<code>.pyc</code> should do it"</li>
          <li>"Python is the most optimized interpreter there is!"</li>
          <li>"Python JIT compilers work!"</li>
          <li>"No matter. The low-level framework does the actual work."</li>
        </ul>
      </section>

      <section class="slide">
        <h3>Opaque Frameworks</h3>
        <br/>
        <ul>
          <li><span class="fancy">Data flow</span> suffers</li>
          <li>Tweaks are <span class="fancy">hard to impossible</span></li>
          <li>Many similarities with <span class="fancy">game engines</span></li>
          <li>Bloat intensifies <img class="diagram" style="position: absolute; top: 255px; left: 20px;" src="laser-eyes.png" /></li>
        </ul>
      </section>

      <section class="slide">
        <h3>Something Good About Python</h3>
        <br/>
        <pre><code class="python hljs">
  slice = a[5:10, :20:2] # slicing is pretty neat
        </code></pre>
        <p style="text-align: right"><small>* Similar syntax coming soon to C++</small></p>
      </section>

      <section>
        <h2>A Crash Course in ML</h2>
      </section>

      <section>
        <p>I am <span class="fancy">not</span> an ML engineer</p>
      </section>

      <section class="slide">
        <h3>Borislav Stanimirov</h3>
        <br/>
        <ul>
          <li>I mostly write <span class="fancy">C++</span></li>
          <li>Professionally since 2002</li>
          <li>2006&mdash;2018: <span class="fancy">game development</span></li>
          <li>2019&mdash;2023: <span class="fancy">medical software</span></li>
          <li>2023&mdash;now: <span class="fancy">machine learning</span></li>
          <li><span class="fancy">Open source</span>: <a href="https://github.com/iboB" target="_blank">github.com/iboB</a></li>
        </ul>
      </section>

      <section class="slide">
        <h3>Borislav Stanimirov</h3>
        <br/>
        <ul>
          <li>C++: <span class="fancy">yes</span></li>
          <li>Low-level: <span class="fancy">yes</span></li>
          <li>GPGPU: <span class="fancy">yes</span></li>
          <li>Chasing microseconds: <span class="fancy">yes</span></li>
          <li>Machine learning: <em>well...</em></li>
        </ul>
      </section>

      <section>
        <p>So, this is my perspective...</p>
      </section>

      <section class="slide">
        <h3>ML Techniques</h3>
        <br/>
        <ul>
          <li>Linear regression</li>
          <li>Bayes classification</li>
          <li>Support vector machine</li>
          <li>Decision tree</li>
          <li>Random forest</li>
          <li>&hellip;</li>
        </ul>
      </section>

      <section>
        <h3>NOPE</h3>
      </section>

      <section>
        <h3>Neural Networks</h3>
      </section>

      <section class="slide">
        <h3>Neural networks</h3>
        <ul>
          <li class="fragment strike">History</li>
        </ul>
      </section>

      <section>
        <p>What is a neural network?</p>
        <p>It's a <span class="fancy">function</span></p>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>
    enum thing { ... };
    thing classifier(const image&amp; input);
        </code></pre>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>
    enum thing { ... };
    struct result {
      thing t;
      float p;
    }
    std::vector&lt;result&gt; classifier(const image&amp; input);
        </code></pre>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>
    std::string gpt(const std::string&amp; input);
        </code></pre>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>
    using gpt_callback = std::function&lt;void(const std::string&amp;)&gt;
    void gpt(const std::string&amp; input, gpt_callback cb);
        </code></pre>
      </section>

      <section>
        <p>What is a neural network?</p>
        <p>It's a <span class="fancy">computation with parameters</span></p>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>
    enum thing { ... };
    thing classifier(const image&amp; input, <span class="hl-code-i">const std::vector&lt;float&gt;&amp; parameters</span>);
        </code></pre>
      </section>

      <section>
        <p><span class="fancy">Parameters</span></p>
        <p><code class="cinline">LLaMa-7B</code> - the LLaMa model with 7 billion parameters</p>
      </section>

      <section class="slide">
        <h3>Training Neural Networks</h3>
        <br/>
        <ul>
          <li>Solve the function with respect to the parameters</li>
          <li>Gradient descent and differentiability</li>
          <li>Learning rate</li>
          <li>Over/Underfitting</li>
          <li>...</li>
        </ul>
      </section>

      <section>
        <h3>NOPE</h3>
      </section>

      <section class="slide">
        <h3>Designing Neural Networks</h3>
        <br/>
        <ul>
          <li><span class="fancy">It's magic</span></li>
          <li>Mostly indistinguishable from fortune telling</li>
          <li><span class="fancy">Years</span> of experience</li>
          <li>Lots of <span class="fancy">untransferrable knowledge</span></li>
          <li>Takes <span class="fancy">millions of hours</span></li>
          <li>It seems that we do need Python here &#x1f622;</li>
        </ul>
      </section>

      <section>
        <h3>NOPE</h3>
      </section>

      <section class="slide">
        <h3>Neural Network Applications</h3>
        <br/>
        <ul>
          <li>Design - not today</li>
          <li>Training - not today</li>
          <li><span class="fancy">Inference</span> - executing the computation - today</li>
          <li>Inference on the edge - tomorrow</li>
        </ul>
      </section>

      <section>
        <p>What is a neural network?</p>
        <p>A network of <span class="fancy">neurons</span>, duh</p>
      </section>

      <section>
        <img class="diagram" src="neuron.png" />
        <p>$y = g \left( \sum_{i=1}^{n} w_j x_j + b \right)$</p>
      </section>

      <section>
        <img class="diagram" src="network.png" />
        <p>Layers</p>
      </section>

      <section>
        <img class="diagram" src="single-layer.png" />
        <p>Wait! I know this</p>
      </section>

      <section>
        <p>$\begin{pmatrix} y_1 \\ y_2 \\ y_3 \end{pmatrix} = g \left( \begin{pmatrix} w_{11} & w_{12} & w_{13} & w_{14} \\ w_{21} & w_{22} & w_{23} & w_{24} \\ w_{31} & w_{32} & w_{33} & w_{14} \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{pmatrix} + \begin{pmatrix} b_1 \\ b_2 \\ b_3 \end{pmatrix} \right)$</p>
        <p>Yes. This is everything</p>
      </section>

      <section class="slide">
        <h3>Types of layers</h3>
        <br/>
        <ul>
          <li>This was the <span class="fancy">linear</span> (fully connected, dense) layer</li>
          <li>Every layer type can be represented by a fully connected one</li>
          <li>It's a matter of efficiency</li>
          <li>Convolution/Pooling</li>
          <li>Attention</li>
          <li>Normalization</li>
          <li>"Layer" actually is pretty <span class="fancy">fuzzy</span></li>
          <li><a href="https://www.asimovinstitute.org/neural-network-zoo/">The Neural Network Zoo</a></li>
        </ul>
      </section>

      <section class="slide">
        <h3>Activation layers</h3>
        <br/>
        <ul>
          <li>Without them every output would be a linear function of the input</li>
          <li><span class="fancy">Layer count wouldn't matter</span></li>
          <li>Sigmoids</li>
          <ul>
            <li>Logistic function</li>
            <li>tanh</li>
            <li>smht</li>
          </ul>
          <li>ReLU</li>
          <li>Leaky ReLU</li>
          <li>GELU</li>
        </ul>
      </section>

      <section>
        <h3>Convolution</h3>
      </section>

      <section>
        <img class="diagram" src="conv2d-01.png" />
        <p>Neurons don't depend on the entire input</p>
      </section>

      <section>
        <img class="diagram" src="conv2d-02.png" />
        <p>Feature maps</p>
      </section>

      <section>
        <h3>Pooling</h3>
      </section>

      <section>
        <img class="diagram" src="pooling.png" />
        <p>Collecting "important" features</p>
      </section>

      <section>
        <p>What is a neural network?</p>
        <p>A collection of layers which define a computation</p>
      </section>

      <section>
        <h3>Terminology time</h3>
      </section>

      <section class="slide">
        <h3>Tensors</h3>
        <ul>
          <li>No, not physical ones.</li>
          <li>Just <span class="fancy">N-d arrays</span></li>
          <li>Think <code class="cinline">std::vector</code></li>
          <li>Shape: <code class="cinline">[[1,2],[3,4],[5,6]] -> (3, 2)</code>... or maybe <code class="cinline">(2, 3)</code></li>
          <li>Broadcast: </li>
          <ul>
            <li><code class="cinline">f([1,2,3]) = [f(1), f(2), f(3)]</code></li>
            <li><code class="cinline">[[1,2],[3,4]] + [10,20] = [[11,22],[13,24]]</code></li>
          </ul>
          <li>Tensors for weight, bias, layer</li>
          <ul>
            <li><code class="cinline">ll_5 = mul(w_5, l_4) + b_5 </code></li>
          </ul>
        </ul>
      </section>

      <section class="slide">
        <h3>Models</h3>
        <br/>
        <ul>
          <li>What is a model anyway?</li>
          <li>Any of:</li>
          <li>The layer/computation sequence</li>
          <li>The parameter (weight) tensors</li>
        </ul>
      </section>

      <section>
        <h2>LeNet</h2>
      </section>

      <section>
        <img class="diagram" src="mnist.png" />
        <p>MNIST dataset</p>
      </section>

      <section>
        <img class="diagram" src="lenet.webp" />
        <p>LeNet Model</p>
      </section>

      <section>
        <pre><code class="python hljs" data-noescape>  class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()

        self.convs = nn.Sequential(
          <span class="fragment hl-code">nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(5, 5)),</span>
          <span class="fragment hl-code">nn.Tanh(),</span>
          <span class="fragment hl-code">nn.AvgPool2d(2, 2),</span>

          <span class="fragment hl-code">nn.Conv2d(in_channels=4, out_channels=12, kernel_size=(5, 5))</span>,
          <span class="fragment hl-code">nn.Tanh()</span>,
          <span class="fragment hl-code">nn.AvgPool2d(2, 2)</span>
        )

        self.linear = nn.Sequential(
          <span class="fragment hl-code">nn.Linear(4*4*12,10)</span>
        )

    def forward(self, x: torch.Tensor):
        <span class="fragment hl-code">x = self.convs(x)</span>
        x = torch.flatten(x, 1)
        <span class="fragment hl-code">x = self.linear(x)</span>
        <span class="fragment hl-code">return nn.functional.softmax(x, dim = 0)</span>
        </code></pre>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>    m_input = create_tensor("input", {28, 28, 1});
    ggml_tensor* next;
    auto conv0_weight = create_weight_tensor("conv0_weight", {5, 5, 1, 4});
    auto conv0_bias = create_weight_tensor("conv0_bias", {1, 1, 4});
    <span class="fragment hl-code">next = ggml_conv_2d(m_ctx, conv0_weight, m_input, 1, 1, 0, 0, 1, 1);</span>
    <span class="fragment hl-code">next = ggml_add(m_ctx, next, <span class="fragment hl-code">ggml_repeat(m_ctx, conv0_bias, next)</span>);</span>
    <span class="fragment hl-code">next = ggml_tanh(m_ctx, next);</span>
    <span class="fragment hl-code">next = ggml_pool_2d(m_ctx, next, GGML_OP_POOL_AVG, 2, 2, 2, 2, 0, 0);</span>
    auto conv1_weight = create_weight_tensor("conv1_weight", {5, 5, 4, 12});
    auto conv1_bias = create_weight_tensor("conv1_bias", {1, 1, 12});
    <span class="fragment hl-code">next = ggml_conv_2d(m_ctx, conv1_weight, next, 1, 1, 0, 0, 1, 1);</span>
    <span class="fragment hl-code">next = ggml_add(m_ctx, next, ggml_repeat(m_ctx, conv1_bias, next));</span>
    <span class="fragment hl-code">next = ggml_tanh(m_ctx, next);</span>
    <span class="fragment hl-code">next = ggml_pool_2d(m_ctx, next, GGML_OP_POOL_AVG, 2, 2, 2, 2, 0, 0);</span>
    <span class="fragment hl-code">next = ggml_reshape_1d(m_ctx, next, 12 * 4 * 4);</span>
    auto linear_weight = create_weight_tensor("linear_weight", {12 * 4 * 4, 10});
    auto linear_bias = create_weight_tensor("linear_bias", {10});
    <span class="fragment hl-code">next = ggml_mul_mat(m_ctx, linear_weight, next);</span>
    <span class="fragment hl-code">next = ggml_add(m_ctx, next, linear_bias);</span>
    <span class="fragment hl-code">m_output = ggml_soft_max(m_ctx, next);</span>
        </code></pre>
      </section>

      <section>
        <h2>Practical Challenges With Inference</h2>
      </section>

      <section class="slide">
        <h3>Number crunching</h3>
        <br/>
        <ul>
          <li>GPGPU is <span class="fancy">the</span> way to go</li>
          <li>SIMD</li>
          <li>gemm</li>
          <li>cache-locality</li>
          <li>Memory bandwitdh is typically the bottleneck - M2 Ultra's time to shine</li>
          <li>Quantizations. Yes, Q2 is a thing</li>
        </ul>
      </section>

      <section class="slide">
        <h3>Tweaks</h3>
        <br/>
        <ul>
          <li>They come more often that you would think</li>
          <li>Quantization</li>
          <li>Reshapes</li>
          <li>Custom kernels</li>
          <li>Sampling and resampling</li>
        </ul>
      </section>

      <section>
        <h2>How to Start?</h2>
      </section>

      <section>
        <p>First implement a simple model in the most naive way!</p>
      </section>

      <section>
        <p>Yes, play with Python, too</p>
        <p class="fragment"><img style="width: 20%" class="diagram" src="../beyond-vec/nope.png" /></p>
      </section>

      <section class="slide">
        <h3>Libs and Frameworks</h3>
        <br/>
        <ul>
          <li>Monsters: PyTorch, TensorFlow/Keras, onnx</li>
          <li><a href="https://github.com/ggerganov/ggml">ggerganov/ggml</a>: Exotic quantizations, CPU, Metal, CUDA</li>
          <li><a href="https://github.com/OpenNMT/CTranslate2">OpenNMT/CTranslate2</a>: CUDA</li>
          <li><a href="https://github.com/Tencent/ncnn">Tencent/ncnn</a>: Vulkan</li>
          <li>NVIDIA CUDA-only bloat: FasterTrasformer, cuDNN, TensorRT</li>
        </ul>
      </section>

      <section class="slide">
        <h3>Examples and Sources</h3>
        <br/>
        <ul>
          <li>ggml examples</li>
          <li><a href="https://github.com/ggerganov/llama.cpp">ggerganov/llama.cpp</a>: LLaMa with ggml</li>
          <li><a href="https://github.com/karpathy/llama2.c">karpathy/llama2.c</a>: LLaMa in pure C</li>
          <li><a href="https://github.com/intel/intel-extension-for-transformers">intel/intel-extension-for-transformers</a>: Intel-specific</li>
          <li>NVIDIA CUDA-only bloat: FasterTrasformer, cuDNN, TensorRT</li>
          <li>And many, many more</li>
        </ul>
      </section>

      <section class="slide">
        <h3>Practical Steps</h3>
        <br/>
        <ul>
          <li>Find a model (for example on HuggingFace)</li>
          <li>Look at the model description if available</li>
          <li>Look at the Python implementation</li>
          <li>Yes, there will be one</li>
          <li>Implement tensor ops</li>
          <li>Compare intermediate steps with the Python implementation</li>
          <li>...</li>
          <li>Profit</li>
        </ul>
      </section>

      <section class="slide">
        <h3>But Why?</h3>
        <br/>
        <ul>
          <li>If you like <span class="fancy">number crunching</span></li>
          <li>If you like <span class="fancy">chasing nanoseconds</span></li>
          <li>If you like <span class="fancy">doing magic</span></li>
          <li>If you don't like "scientific" code</li>
        </ul>
      </section>

      <section>
        <p>You are needed!</p>
      </section>

      <section class="fin">
        <span class="fragment">
        <h2>End</h2>
        <h3>Questions?</h3>
        </span>
        <ul>
          <!-- <li>Demo code: <a href="https://github.com/iboB/ai-cpp-demo/">github.com/iboB/ai-cpp-demo</a></li> -->
          <li>These slides: <a href="https://ibob.bg/slides/ai-cpp-intro/">ibob.bg/slides/ai-cpp-intro/</a></li>
          <li>Borislav Stanimirov / <a href="https://ibob.bg">ibob.bg</a> / <a href="https://twitter.com/stanimirovb">@stanimirovb</a></li>
        </ul>
        <br/>
        <br/>
        <p class="fragment"><small>Slides license: <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a>&nbsp;&nbsp;&nbsp;<a rel="license" href="https://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" class="diagram" style="height: 1.2em" src="http://i.creativecommons.org/l/by/4.0/88x31.png" /></a></small></p>
      </section>

    </div>
  </div>

  <script src="../lib/reveal.js-3.8.0/js/reveal.min.js"></script>
  <script src="../lib/slides.js"></script>

  <script>
    Reveal.initialize({
      width: 1280,
      height: 720,

      controls: true,
      progress: true,
      history: true,
      center: true,

      transition: 'none', // none/fade/slide/convex/concave/zoom

      autoPlayMedia: false,
      preloadIframes: false,

      // Optional libraries used to extend on reveal.js
      dependencies: [
        //{ src: 'markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        //{ src: 'markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'highlight/highlight.min.js', async: true, callback: function() {
          hljs.initHighlightingOnLoad();
        } },
        //{ src: 'zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
        //{ src: 'notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
        // MathJax
		    { src: 'math/math.js', async: true }
      ].map(p => { p.src = '../lib/reveal.js-3.8.0/plugin/' + p.src; return p; })
    });

    slides.footerSetup('is.gd/aicppintro', '2022');
  </script>

</body>
</html>
