<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">

  <title>AI Without Python</title>

  <meta name="description" content="Slides for an introductory talk about AI and ML for C++ programmers">
  <meta name="author" content="Borislav Stanimirov">

  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  <link rel="stylesheet" href="../lib/reveal.js-3.8.0/css/reveal.min.css" />
  <link rel="stylesheet" href="../lib/reveal.js-3.8.0/css/theme/simple.min.css" id="theme" />
  <link rel="stylesheet" href="../lib/slides.css" />

  <!-- For syntax highlighting -->
  <link rel="stylesheet" href="/third_party/highlight-new/styles/github-gist.css">

  <!-- Slides-specific styles -->
  <link rel="stylesheet" href="custom.css">

  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ?
      'https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.8.0/css/print/pdf.min.css' :
      'https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.8.0/css/print/paper.min.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>

  <!--[if lt IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.8.0/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>

<body>

  <div class="reveal">
    <div class="slides">
      <section class="title">
        <h1>AI Without Python</h1>
        <h2>An Intro to Machine Learning for C++ Programmers</h2>
        <br/>
        <p>
          <a href="http://ibob.bg">Borislav Stanimirov</a> / <a href="https://twitter.com/stanimirovb">@stanimirovb</a>
        </p>
      </section>

      <section class="slide">
        <h3>Hello, World</h3>
        <br/>
        <pre><code class="cpp hljs" data-noescape>
  #include &lt;iostream&gt;

  int main()
  {
      std::cout &lt;&lt; "Hi, I'm Borislav!\n";
      std::cout &lt;&lt; "These slides are here: <span class="fragment hl-code">https://is.gd/aicppintro</span>\n";
      return 0;
  }
        </code></pre>
      </section>

      <section class="slide">
        <h3>Borislav Stanimirov</h3>
        <br/>
        <ul>
          <li>I mostly write <span class="fancy">C++</span></li>
          <li>Professionally since 2002</li>
          <li>2006&mdash;2018: <span class="fancy">game development</span></li>
          <li>2019&mdash;2023: <span class="fancy">medical software</span></li>
          <li>2023&mdash;now: <span class="fancy">machine learning</span></li>
          <li><span class="fancy">Open source</span>: <a href="https://github.com/iboB" target="_blank">github.com/iboB</a></li>
        </ul>
      </section>

      <section class="slide">
        <h3>This talk</h3>
        <br/>
        <ul>
          <li class="fragment">&#x26a0;&#xfe0f; More <span class="fancy">inspirational</span> than educational</li>
          <li class="fragment">&#x26a0;&#xfe0f; Contains <span class="fancy">personal opinion</span> on software</li>
          <li class="fragment">More <span class="fancy">technical</span> than philosophical</li>
          <li class="fragment">The <span class="fancy">gist</span>, rather than the detail</li>
          <li class="fragment">Mainly for programmers who are <span class="fancy">not</span> in the ML field</li>
          <li class="fragment">... and who have experience or interest in <span class="fancy">low-level</span></li>
          <li class="fragment">Themes</li>
          <ul class="fragment">
            <li><em>Why should you consider this?</em></li>
            <li><em>What can you do?</em></li>
          </ul>
        </ul>
      </section>

      <section>
        <h2>Background</h2>
        <h3>Machine Learning in 2023</h3>
      </section>

      <section>
        <h3>The Current <span class="fancy">Big Thing&trade;</span> in software</h3>
      </section>

      <section>
        <p>Whisper, DALL&middot;E, Craiyon &#x1f58d;, ChatGPT, GPT-J, LLaMa &#x1f999;, LaMDA,
          Midjourney, Falcon LLM &#x1f985;, Stable Diffusion, Unstable Diffusion &#x1f609;,
          GitHub Copilot, StarCoder, BERT &#x1F43B;, SAM, Chinchilla &#x1F42D;</p>
        <p>&hellip;</p>
      </section>

      <section>
        <p>A Cambrian explosion of AI tools</p>
        <p class="fragment">... and startups</p>
        <p class="fragment">... and software as a whole</p>
      </section>

      <section>
        <p>There's something new every day.</p>
        <small class="fragment">(this talk will probably be outdated by tomorrow)</small>
      </section>

      <section>
        <p>This software is <span class="fancy">no magic</span></p>
      </section>

      <section class="slide">
        <h3>Modern AI Software</h3>
        <br/>
        <ul>
          <li class="fragment">In many regards software <span class="fancy">like any other</span></li>
          <li class="fragment">Written by teams <span class="fragment">(of humans)</span></li>
          <li class="fragment">...with conventional software development tools</li>
          <li class="fragment">It has <em>some</em> unusual, <span class="fancy">but not unique</span>, features</li>
          <li class="fragment">Many libraries and frameworks exist to help</li>
          <li class="fragment">It's most often done in <span class="fancy">Python</span></li>
        </ul>
      </section>

      <section class="slide">
        <h3>Python Stacks</h3>
        <br/>
        <ul>
          <li class="fragment">The big fish: <span class="fancy">PyTorch</span> and <span class="fancy">TensorFlow</span></li>
          <li class="fragment">Every ML framwork has a Python front end</li>
          <li class="fragment">Why Python?</li>
        </ul>
        <p class="fragment pinner"><img class="diagram" src="../xmem-shared-ptr/dunno.jpg"/></p>
      </section>

      <section>
        <p>&#x26a0;&#xfe0f; Personal opinion time &#x26a0;&#xfe0f;</p>
      </section>

      <section class="slide">
        <h3>Borislav on Python</h3>
        <br/>
        <ul>
          <li class="fragment">Is Python the best language for ML?</li>
          <ul class="fragment">
            <li>No.</li>
          </ul>
          <li class="fragment">It it the worst language for ML?</li>
          <ul>
            <li class="fragment">No. <span class="fragment">But it's down there</span></li>
          </ul>
          <li class="fragment"><span class="fancy">Extreme care</span> is needed for software in duck-typed languages</li>
          <li class="fragment">Python stacks are <span class="fancy">a mess</span></li>
        </ul>
      </section>

      <section>
        <img src="node_modules.png" />
      </section>

      <section class="slide">
        <h3>Python Stacks</h3>
        <br/>
        <ul>
          <li class="fragment">Package managers: pip, pipenv, poetry, npm, conda</li>
          <li class="fragment">Env managers: conda, mamba, pyenv, containers</li>
          <li class="fragment">Notebooks and <span class="fancy"><em>Scientific</em> code</span></li>
        </ul>
      </section>

      <section>
        <h3>Modern ML software</h3>
        <img class="diagram" src="../unrealized-alpha/moms-spaghetti.jpg" />
      </section>

      <section>
        <img class="diagram" src="eye-of-providence.png" />
        <h3>Objective Truth</h3>
      </section>

      <section>
        <p>Python is slow</p>
        <img class="diagram" src="python-slow.jpg" />
      </section>

      <section>
        <p><span class="fancy">"No it's not slow!"</span></p>
        <ul>
          <li class="fragment">"This Python program is faster than its C++ equivalent!"</li>
          <li class="fragment">"<code>.pyc</code> should do it"</li>
          <li class="fragment">"Python is the most optimized interpreter there is!"</li>
          <li class="fragment">"Python JIT compilers work!"</li>
          <li class="fragment">"No matter. The low-level framework does the actual work."</li>
        </ul>
      </section>

      <section class="slide">
        <h3>Opaque Frameworks</h3>
        <br/>
        <ul>
          <li class="fragment"><span class="fancy">Data flow</span> suffers</li>
          <li class="fragment">Tweaks are <span class="fancy">hard to impossible</span></li>
          <li class="fragment">Many similarities with <span class="fancy">game engines</span></li>
          <li class="fragment">Bloat intensifies <img class="diagram" style="position: absolute; top: 255px; left: 20px;" src="laser-eyes.png" /></li>
        </ul>
      </section>

      <section class="slide">
        <h3>Something Good About Python</h3>
        <br/>
        <pre class="fragment"><code class="python hljs">
  slice = a[5:10, :20:2] # slicing is pretty neat
        </code></pre>
        <p class="fragment" style="text-align: right"><small>* Similar syntax coming soon to C++</small></p>
      </section>

      <section>
        <h2>A Crash Course in ML</h2>
      </section>

      <section>
        <p>I am <span class="fancy">not</span> an ML engineer</p>
      </section>

      <section class="slide">
        <h3>Borislav Stanimirov</h3>
        <br/>
        <ul>
          <li>I mostly write <span class="fancy">C++</span></li>
          <li>Professionally since 2002</li>
          <li>2006&mdash;2018: <span class="fancy">game development</span></li>
          <li>2019&mdash;2023: <span class="fancy">medical software</span></li>
          <li>2023&mdash;now: <span class="fancy">machine learning</span></li>
          <li><span class="fancy">Open source</span>: <a href="https://github.com/iboB" target="_blank">github.com/iboB</a></li>
        </ul>
      </section>

      <section class="slide">
        <h3>Borislav Stanimirov</h3>
        <br/>
        <ul>
          <li class="fragment">C++: <span class="fancy">yes</span></li>
          <li class="fragment">Low-level: <span class="fancy">yes</span></li>
          <li class="fragment">GPGPU: <span class="fancy">yes</span></li>
          <li class="fragment">Chasing microseconds: <span class="fancy">yes</span></li>
          <li class="fragment">Machine learning: <em class="fragment">well...</em></li>
        </ul>
      </section>

      <section>
        <p>So, this is my perspective...</p>
      </section>

      <section class="slide">
        <h3>ML Techniques</h3>
        <br/>
        <ul>
          <li>Linear regression</li>
          <li>Bayes classification</li>
          <li>Support vector machine</li>
          <li>Decision tree</li>
          <li>Random forest</li>
          <li>&hellip;</li>
        </ul>
      </section>

      <section>
        <h3>NOPE</h3>
      </section>

      <section>
        <h3>Neural Networks</h3>
      </section>

      <section class="slide">
        <h3>Neural networks</h3>
        <ul>
          <li class="fragment strike">History</li>
        </ul>
      </section>

      <section>
        <p>What is a neural network?</p>
        <p class="fragment">It's a <span class="fancy">function</span></p>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>
    enum thing { ... };
    thing classifier(const image&amp; input);
        </code></pre>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>
    enum thing { ... };
    struct result {
      thing t;
      float p;
    }
    std::vector&lt;result&gt; classifier(const image&amp; input);
        </code></pre>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>
    std::string gpt(const std::string&amp; input);
        </code></pre>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>
    using gpt_callback = std::function&lt;void(const std::string&amp;)&gt;
    void gpt(const std::string&amp; input, gpt_callback cb);
        </code></pre>
      </section>

      <section>
        <p>What is a neural network?</p>
        <p class="fragment">It's a <span class="fancy">computation with parameters</span></p>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>
    enum thing { ... };
    thing classifier(const image&amp; input, <span class="hl-code-i">const std::vector&lt;float&gt;&amp; parameters</span>);
        </code></pre>
      </section>

      <section>
        <p><span class="fancy">Parameters</span></p>
        <p><code class="cinline">LLaMa-7B</code> - the LLaMa model with 7 billion parameters</p>
      </section>

      <section class="slide">
        <h3>Training Neural Networks</h3>
        <br/>
        <ul>
          <li class="fragment">Solve the function with respect to the parameters</li>
          <li class="fragment">Gradient descent and differentiability</li>
          <li class="fragment">Learning rate</li>
          <li class="fragment">Over/Underfitting</li>
          <li class="fragment">...</li>
        </ul>
      </section>

      <section>
        <h3>NOPE</h3>
      </section>

      <section class="slide">
        <h3>Designing Neural Networks</h3>
        <br/>
        <ul>
          <li class="fragment"><span class="fancy">It's magic</span></li>
          <li class="fragment">Mostly indistinguishable from fortune telling</li>
          <li class="fragment"><span class="fancy">Years</span> of experience</li>
          <li class="fragment">Lots of <span class="fancy">untransferrable knowledge</span></li>
          <li class="fragment">Takes <span class="fancy">millions of hours</span></li>
          <li class="fragment">It seems that we do need Python here &#x1f622;</li>
        </ul>
      </section>

      <section>
        <h3>NOPE</h3>
      </section>

      <section class="slide">
        <h3>Neural Network Applications</h3>
        <br/>
        <ul>
          <li class="fragment">Design - not today</li>
          <li class="fragment">Training - not today</li>
          <li class="fragment"><span class="fancy">Inference</span> - executing the computation - today</li>
          <li class="fragment">Inference on the edge - tomorrow</li>
        </ul>
      </section>

      <section>
        <p>What is a neural network?</p>
        <p class="fragment">A network of <span class="fancy">neurons</span>, duh</p>
      </section>

      <section>
        <img class="diagram" src="neuron.png" />
        <p>$y = g \left( \sum_{i=1}^{n} w_j x_j + b \right)$</p>
      </section>

      <section>
        <img class="diagram" src="network.png" />
        <p>Layers</p>
      </section>

      <section>
        <img class="diagram" src="single-layer.png" />
        <p class="fragment">Wait! I know this</p>
      </section>

      <section>
        <p>$\begin{pmatrix} y_1 \\ y_2 \\ y_3 \end{pmatrix} = g \left( \begin{pmatrix} w_{11} & w_{12} & w_{13} & w_{14} \\ w_{21} & w_{22} & w_{23} & w_{24} \\ w_{31} & w_{32} & w_{33} & w_{14} \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{pmatrix} + \begin{pmatrix} b_1 \\ b_2 \\ b_3 \end{pmatrix} \right)$</p>
        <p class="fragment">Yes. This is mostly everything</p>
      </section>

      <section class="slide">
        <h3>Types of layers</h3>
        <br/>
        <ul>
          <li class="fragment">This was the <span class="fancy">linear</span> (fully connected, dense) layer</li>
          <li class="fragment">Almost all layer types can be represented as fully connected</li>
          <li class="fragment">It's a matter of efficiency</li>
          <li class="fragment">Convolution/Pooling layers</li>
          <li class="fragment">Normalization layers</li>
          <li class="fragment">Attention layers</li>
          <li class="fragment">"Layer" actually <em>is</em> pretty <span class="fancy">fuzzy</span></li>
          <li class="fragment"><a href="https://www.asimovinstitute.org/neural-network-zoo/">The Neural Network Zoo</a></li>
        </ul>
      </section>

      <section class="slide">
        <h3>Activation layers</h3>
        <br/>
        <ul>
          <li class="fragment">Without them every output would be a linear function of the input</li>
          <li class="fragment"><span class="fancy">Layer count wouldn't matter</span></li>
          <li class="fragment">Sigmoids</li>
          <ul class="fragment">
            <li>Logistic function</li>
            <li>tanh</li>
            <li>smht</li>
          </ul>
          <li class="fragment">ReLU</li>
          <li class="fragment">Leaky ReLU</li>
          <li class="fragment">GELU</li>
        </ul>
      </section>

      <section>
        <h3>Convolution</h3>
      </section>

      <section>
        <img class="diagram" src="conv2d-01.png" />
        <p class="fragment">Neurons don't depend on the entire input</p>
        <p class="fragment">Weights are shared</p>
      </section>

      <section>
        <img class="diagram" src="conv2d-02.png" />
        <p>Feature maps</p>
      </section>

      <section>
        <h3>Pooling</h3>
      </section>

      <section>
        <img class="diagram" src="pooling.png" />
        <p class="fragment">Collecting "important" features</p>
      </section>

      <section>
        <p>What is a neural network?</p>
        <p class="fragment"><span class="fancy">A collection of layers which define a computation</span></p>
      </section>

      <section>
        <h3>Terminology time</h3>
      </section>

      <section class="slide">
        <h3>Tensors</h3>
        <ul>
          <li class="fragment">No, not physical ones.</li>
          <li class="fragment">Just <span class="fancy">N-d arrays</span></li>
          <li class="fragment">Think <code class="cinline">std::vector</code></li>
          <li class="fragment">Shape: <code class="cinline">[[1,2],[3,4],[5,6]] -> (3, 2)</code>... or maybe <code class="cinline">(2, 3)</code></li>
          <li class="fragment">Broadcast: </li>
          <ul class="fragment">
            <li><code class="cinline">f([1,2,3]) = [f(1), f(2), f(3)]</code></li>
            <li><code class="cinline">[[1,2],[3,4]] + [10,20] = [[11,22],[13,24]]</code></li>
          </ul>
          <li class="fragment">Tensors for weight, bias, layer</li>
          <ul class="fragment">
            <li><code class="cinline">ll_5 = mul(w_5, l_4) + b_5 </code></li>
          </ul>
        </ul>
      </section>

      <section class="slide">
        <h3>Models</h3>
        <br/>
        <ul>
          <li class="fragment">What is a model anyway?</li>
          <li class="fragment">Any of:</li>
          <ul>
            <li class="fragment">The layer/computation sequence</li>
            <li class="fragment">The parameter (weight) tensors</li>
          </ul>
        </ul>
      </section>

      <section>
        <h2>LeNet</h2>
        <p class="fragment">AI like it's 1989</p>
      </section>

      <section>
        <img class="diagram" src="mnist.png" />
        <p>MNIST dataset</p>
      </section>

      <section>
        <img class="diagram" src="lenet.webp" />
        <p>LeNet Model</p>
      </section>

      <section>
        <pre><code class="python hljs" data-noescape>  class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()

        self.convs = nn.Sequential(
          <span class="fragment hl-code">nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(5, 5)),</span>
          <span class="fragment hl-code">nn.Tanh(),</span>
          <span class="fragment hl-code">nn.AvgPool2d(2, 2),</span>

          <span class="fragment hl-code">nn.Conv2d(in_channels=4, out_channels=12, kernel_size=(5, 5))</span>,
          <span class="fragment hl-code">nn.Tanh()</span>,
          <span class="fragment hl-code">nn.AvgPool2d(2, 2)</span>
        )

        self.linear = nn.Sequential(
          <span class="fragment hl-code">nn.Linear(4*4*12,10)</span>
        )

    def forward(self, x: torch.Tensor):
        <span class="fragment hl-code">x = self.convs(x)</span>
        x = torch.flatten(x, 1)
        <span class="fragment hl-code">x = self.linear(x)</span>
        <span class="fragment hl-code">return nn.functional.softmax(x, dim = 0)</span>
        </code></pre>
      </section>

      <section>
        <pre><code class="cpp hljs" data-noescape>    m_input = create_tensor("input", {28, 28, 1});
    ggml_tensor* next;
    auto conv0_weight = create_weight_tensor("conv0_weight", {5, 5, 1, 4});
    auto conv0_bias = create_weight_tensor("conv0_bias", {1, 1, 4});
    <span class="fragment hl-code">next = ggml_conv_2d(m_ctx, conv0_weight, m_input, 1, 1, 0, 0, 1, 1);</span>
    <span class="fragment hl-code">next = ggml_add(m_ctx, next, <span class="fragment hl-code">ggml_repeat(m_ctx, conv0_bias, next)</span>);</span>
    <span class="fragment hl-code">next = ggml_tanh(m_ctx, next);</span>
    <span class="fragment hl-code">next = ggml_pool_2d(m_ctx, next, GGML_OP_POOL_AVG, 2, 2, 2, 2, 0, 0);</span>
    auto conv1_weight = create_weight_tensor("conv1_weight", {5, 5, 4, 12});
    auto conv1_bias = create_weight_tensor("conv1_bias", {1, 1, 12});
    <span class="fragment hl-code">next = ggml_conv_2d(m_ctx, conv1_weight, next, 1, 1, 0, 0, 1, 1);</span>
    <span class="fragment hl-code">next = ggml_add(m_ctx, next, ggml_repeat(m_ctx, conv1_bias, next));</span>
    <span class="fragment hl-code">next = ggml_tanh(m_ctx, next);</span>
    <span class="fragment hl-code">next = ggml_pool_2d(m_ctx, next, GGML_OP_POOL_AVG, 2, 2, 2, 2, 0, 0);</span>
    <span class="fragment hl-code">next = ggml_reshape_1d(m_ctx, next, 12 * 4 * 4);</span>
    auto linear_weight = create_weight_tensor("linear_weight", {12 * 4 * 4, 10});
    auto linear_bias = create_weight_tensor("linear_bias", {10});
    <span class="fragment hl-code">next = ggml_mul_mat(m_ctx, linear_weight, next);</span>
    <span class="fragment hl-code">next = ggml_add(m_ctx, next, linear_bias);</span>
    <span class="fragment hl-code">m_output = ggml_soft_max(m_ctx, next);</span>
        </code></pre>
      </section>

      <section>
        <h2>Practical Challenges With Inference</h2>
      </section>

      <section class="slide">
        <h3>Number crunching</h3>
        <br/>
        <ul>
          <li class="fragment">GPGPU is <span class="fancy">the</span> way to go</li>
          <li class="fragment">SIMD</li>
          <li class="fragment">gemm</li>
          <li class="fragment">cache-locality</li>
          <li class="fragment">Memory bandwitdh bottlenecks <span class="fragment">- M2 Ultra's time to shine</span></li>
          <li class="fragment">Quantizations. Yes, Q2 is a thing</li>
        </ul>
      </section>

      <section class="slide">
        <h3>Tweaks</h3>
        <br/>
        <ul>
          <li class="fragment">They come more often that you would think</li>
          <li class="fragment">Quantization</li>
          <li class="fragment">Reshapes</li>
          <li class="fragment">Custom kernels</li>
          <li class="fragment">Sampling and resampling</li>
        </ul>
      </section>

      <section>
        <h2>How to Start?</h2>
      </section>

      <section>
        <p>First implement a simple model in the most naive way!</p>
      </section>

      <section>
        <p>Yes, play with Python, too</p>
        <p class="fragment"><img style="width: 20%" class="diagram" src="../beyond-vec/nope.png" /></p>
      </section>

      <section class="slide">
        <h3>Libs and Frameworks</h3>
        <br/>
        <ul>
          <li class="fragment">Monsters: PyTorch, TensorFlow/Keras, onnx</li>
          <li class="fragment"><a href="https://github.com/ggerganov/ggml">ggerganov/ggml</a>: Exotic quantizations, CPU, Metal, CUDA</li>
          <li class="fragment"><a href="https://github.com/OpenNMT/CTranslate2">OpenNMT/CTranslate2</a>: CUDA</li>
          <li class="fragment"><a href="https://github.com/Tencent/ncnn">Tencent/ncnn</a>: Vulkan</li>
          <li class="fragment">NVIDIA CUDA-only bloat: FasterTrasformer, cuDNN, TensorRT</li>
        </ul>
      </section>

      <section class="slide">
        <h3>Examples and Sources</h3>
        <br/>
        <ul>
          <li class="fragment"><a href="https://huggingface.co/">Huggging Face</a>: models, datasets, spaces</li>
          <li class="fragment">ggml examples</li>
          <li class="fragment"><a href="https://github.com/ggerganov/llama.cpp">ggerganov/llama.cpp</a>: LLaMa with ggml</li>
          <li class="fragment"><a href="https://github.com/karpathy/llama2.c">karpathy/llama2.c</a>: LLaMa in pure C</li>
          <li class="fragment"><a href="https://github.com/intel/intel-extension-for-transformers">intel/intel-extension-for-transformers</a>: Intel-specific</li>
          <li class="fragment">NVIDIA CUDA-only bloat: FasterTrasformer, cuDNN, TensorRT</li>
          <li class="fragment">And many, many more</li>
        </ul>
      </section>

      <section class="slide">
        <h3>Practical Steps</h3>
        <br/>
        <ol>
          <li class="fragment">Find a model (for example on Hugging Face)</li>
          <li class="fragment">Look at the model description if available</li>
          <li class="fragment">Look at the Python implementation</li>
          <li class="fragment">Yes, there will be one</li>
          <li class="fragment">Implement tensor ops</li>
          <li class="fragment">Compare intermediate steps with the Python implementation</li>
          <li class="fragment">...</li>
          <li class="fragment">Profit</li>
        </ol>
      </section>

      <section class="slide">
        <h3>But Why?</h3>
        <br/>
        <ul>
          <li>If you like <span class="fancy">number crunching</span></li>
          <li>If you like <span class="fancy">chasing microseconds</span></li>
          <li>If you like <span class="fancy">doing magic</span></li>
          <li>If you don't like "scientific" code</li>
        </ul>
      </section>

      <section>
        <p>You are needed!</p>
      </section>

      <section class="fin">
        <span class="fragment">
        <h2>End</h2>
        <h3>Questions?</h3>
        </span>
        <ul>
          <!-- <li>Demo code: <a href="https://github.com/iboB/ai-cpp-demo/">github.com/iboB/ai-cpp-demo</a></li> -->
          <li>These slides: <a href="https://ibob.bg/slides/ai-cpp-intro/">ibob.bg/slides/ai-cpp-intro/</a></li>
          <li>Borislav Stanimirov / <a href="https://ibob.bg">ibob.bg</a> / <a href="https://twitter.com/stanimirovb">@stanimirovb</a></li>
        </ul>
        <br/>
        <br/>
        <p class="fragment"><small>Slides license: <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a>&nbsp;&nbsp;&nbsp;<a rel="license" href="https://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" class="diagram" style="height: 1.2em" src="http://i.creativecommons.org/l/by/4.0/88x31.png" /></a></small></p>
      </section>

    </div>
  </div>

  <script src="../lib/reveal.js-3.8.0/js/reveal.min.js"></script>
  <script src="../lib/slides.js"></script>

  <script>
    Reveal.initialize({
      width: 1280,
      height: 720,

      controls: true,
      progress: true,
      history: true,
      center: true,

      transition: 'none', // none/fade/slide/convex/concave/zoom

      autoPlayMedia: false,
      preloadIframes: false,

      // Optional libraries used to extend on reveal.js
      dependencies: [
        //{ src: 'markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        //{ src: 'markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'highlight/highlight.min.js', async: true, callback: function() {
          hljs.initHighlightingOnLoad();
        } },
        //{ src: 'zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
        //{ src: 'notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
        // MathJax
		    { src: 'math/math.js', async: true }
      ].map(p => { p.src = '../lib/reveal.js-3.8.0/plugin/' + p.src; return p; })
    });

    slides.footerSetup('is.gd/aicppintro', '2023', 'v1.0.0');
  </script>

</body>
</html>
